#+TITLE: Project Title:MINDSTREAM: Decoding Brain Signals into Text with NLP
#+AUTHOR: akshata:,kritika:, yanli


* Table of Contents
- [[#abstract][Abstract]]
- [[#Introduction][Introduction]]
- [[#Dataset][ Description]]
    - [[#Dataset details][Dataset details]]
    - [[#Pre-processing][Pre-processing]]
- [[#Literature Review][Literature Review]]
- [[#Methods and Materials][Methods and Materials]]
    - [[#Model pipeline][Model pipeline]]
    - [[#Model Architecture][Model Architetcure]]
    - [[#Implementation Details][Implementation Details]]
- [[#Results and Evaluation][Results and Evaluation]]
- [[#Challenges][Challenges]]
- [[#Conclusion][Conclusion]]
- [[#Future Works][Future Works]]
- [[#Code Description][Code Description]]
- [[#Refrences][References]]

#+name: abstract
* Abstract2:
Brain-Computer Interfacing (BCI) holds immense potential for revolutionizing human-computer interaction by directly translating brain activity into actionable commands. In this project, we explore the application of BCI technology in the realm of natural language processing (NLP) through the analysis of electroencephalography (EEG) data. Leveraging the ZuCo dataset, we investigate the feasibility of decoding EEG signals into textual representations and further extend our analysis to sentiment classification tasks.

Our methodology involves the utilization of deep learning models to process EEG signals and extract meaningful features for downstream NLP tasks. We employ state-of-the-art pre-trained models for embeddings to enhance the representational power of our EEG data. Through rigorous experimentation and evaluation, we assess the performance of various deep learning architectures in transforming EEG data into textual and sentiment-related information.

The results of our study demonstrate the potential of BCI technology in bridging the gap between neural signals and natural language, showcasing promising capabilities in tasks such as EEG-to-text translation and sentiment analysis. Our findings contribute to the growing body of research in BCI applications and highlight avenues for future exploration in the intersection of neuroscience and natural language processing.Your paragraph text here. You can write multiple lines and they will all be justified aligned.



* 1. Introduction:

Our project "MINDSTREAM: Decoding Brain Signals into Text with NLP" explores the intriguing intersection of brain-computer interfacing (BCI) and natural language processing (NLP). While BCI technology has made remarkable strides in restoring motor functionalities for individuals with disabilities through motor imagery, decoding natural language directly from brain signals remains a formidable challenge. Previous approaches have encountered limitations in vocabulary size, device dependency, and articulation variability.This project extends the scope of BCI applications by transitioning from closed to open vocabulary EEG-to-text sequence-to-sequence decoding and zero-shot sentiment classification. Leveraging the ZuCo dataset and non-invasive EEG recordings, in this study we work on using deep learning models and pre-trained language embeddings to capture complex linguistic information from brain signals.

Inspired by recent advancements in large-scale pretrained language models such as BERT and GPT, the project explores the transfer learning capabilities of these models for EEG-to-text decoding. By fine-tuning pretrained language models and additional projection layers, the study aims to unlock contextualized representations of brain signals, encompassing syntactic and semantic features.

Moreover, the project underscores the importance of non-invasive EEG data due to its high temporal resolution and accessibility. While invasive devices like ECoG may offer superior performance, EEG provides a cost-effective and readily available alternative, crucial for training data-hungry models. Most importantly, this project aims at introducing novel tasks in open vocabulary EEG decoding and EEG-based sentiment classification taking inspirations from existing literatures and explores about how we are  marking towards a significant step forward in BCI-NLP integration. Integrating the  pretrained language models and non-invasive EEG data, we try to shed some light on the potential of BCI technology as a transformative tool for human-machine interaction in diverse domains.

* 1.1 What is EEG signals?

EEG (Electroencephalography) signals are recordings of electrical activity generated by the brain, measured by placing electrodes on the scalp. These signals reflect the synchronized activity of large groups of neurons and are widely used in neuroscience to study brain function in various cognitive processes.

#+ATTR_ORG: :width 300 :height 200 :center
[[file:../Figures/EEG_data_collection.jpg]]

* 1.2 Understanding how brain works during reading or thinking: Simplifying Brain Processes
When it comes to reading and thinking, EEG provides valuable insights into the underlying neural mechanisms. During reading, specific patterns of brain activity emerge, reflecting the processing of visual information, language comprehension, and memory retrieval. Different stages of reading, such as word recognition, semantic processing, and comprehension, are associated with distinct EEG signatures. Similarly, during thinking or cognitive tasks, EEG reveals patterns of neural synchronization and oscillatory activity across different brain regions. Mental processes involved in reading and thinking, such as attention, working memory, and executive functions, can be inferred from EEG signals. By analyzing these EEG patterns, researchers can gain a deeper understanding of how the brain processes information during reading and thinking tasks, shedding light on cognition and its underlying neural basis.
#+ATTR_ORG: :width 300 :height 200 :center
[[file:../Figures/Brain_signals.jpg]]

- Attention: The ability to focus on specific stimuli while ignoring others. beta waves (13-30 Hz) and gamma waves (30-100 Hz) in the frontal and parietal lobes.
- Memory: The process of encoding, storing, and retrieving information. Differences in theta waves (4-7 Hz) and gamma waves during encoding and retrieval processes.
- Language comprehension: The ability to understand and interpret language. Semantic processing (e.g., N400 component) and syntactic processing (e.g., P600 component)

#+ATTR_ORG: :width 300 :height 200 :center
[[file:../Figures/EEG_signals.png]]

* 1.3 Decoding EEG to text and its importance:
- Communication for disabled individuals: such as locked-in syndrome or severe motor disabilities, to express themselves through text.
- Brain-computer interfaces (BCIs): BCIs can enable control of computers, prosthetic devices, and other technologies using only brain activity.
- Understanding brain function: can provide valuable insights into the neural mechanisms underlying language production and comprehension.
- Medical applications: EEG-based text decoding can aid in diagnosing and monitoring neurological disorders such as epilepsy, sleep disorders, and cognitive impairments.
- Assistive technology: Decoding EEG to text can be used to develop assistive technologies that enhance communication and quality of life for individuals with disabilities.

2. Dataset:
  
2.1 Zuco Dataset Description:

The Zurich Cognitive Language Processing Corpus (ZuCo) is a valuable resource for studying language processing, incorporating simultaneous eye-tracking and electroencephalography (EEG) data during natural reading and linguistic annotation tasks. ZuCo 2.0, introduced in the paper "ZuCo 2.0: A dataset of simultaneous EEG and eye-tracking recordings during natural reading" by P. Lüdtke et al., expands upon its predecessor, ZuCo 1.0, with additional data and improved methodologies. Comprising 739 sentences, ZuCo 2.0 includes 349 sentences from standard reading paradigms and 390 from task-specific linguistic annotation tasks. These tasks involve participants actively seeking specific semantic relations within sentences. The dataset provides comprehensive insights into cognitive processes during language comprehension, offering researchers a rich resource to explore the neural correlates of reading and linguistic processing. Moreover, ZuCo 2.0 complements ZuCo 1.0 by enhancing the breadth and depth of available data, facilitating more robust analyses and discoveries in the field of cognitive neuroscience and natural language processing. The zuco dataset can be downloaded from below link: [[https://osf.io/2urht/wiki/home/][Zuco_dataset_link]]

2.4.1 Data Preprocessing: Eye Tracking

* Data Acquisition: Eye position and pupil size were recorded using an EyeLink 1000 Plus tracker at 500 Hz.
* Calibration: The eye tracker was calibrated with a 9-point grid before each paradigm, ensuring accuracy of gaze data.
* Preprocessing:
  Saccades were detected based on velocity and acceleration thresholds.
  Fixations were defined as periods without saccades.
  Blinks were identified as periods with zero pupil diameter or zero gaze positions.
  Fixations within the boundaries of each displayed word were extracted for analysis.
* Feature Extraction:
  Gaze duration (GD), total reading time (TRT), first fixation duration (FFD), single fixation duration (SFD), and go-past time (GPT) were extracted for each word.
  Pupil size was computed for each of these eye-tracking features.
  Number of fixations and mean pupil size were extracted for each word and sentence.
* Gaussian Mixture Model:
  A Gaussian mixture model was trained on gaze data for each sentence to improve allocation of fixations to text lines.
  Exclusion Criteria: Fixations shorter than 100 ms were excluded from the analyses, as they are unlikely to be relevant for reading.
  
2.4.2 Data Pre-processing: EEG data

* Data Acquisition: EEG data were recorded using 105 scalp electrodes and 9 EOG channels.
* Preprocessing Steps:
  EEG data were imported into MATLAB and triggers/latencies were extracted.
  Bad electrodes were identified and replaced based on the EEGLab plugin clean_rawdata.
  EEG data were high-pass filtered at 0.5 Hz and notch filtered at 49-51 Hz.
  Eye artifacts were removed by regressing EOG channels from scalp EEG channels.
  MARA algorithm was used for automatic artifact rejection.
  Bad electrodes were interpolated using spherical spline interpolation.
  EEG and eye-tracking data were synchronized.
* Frequency Band Analysis:
  Band-pass filtering was applied to extract data for five frequency bands.
  Hilbert transform was used to compute the amplitude of each frequency band.
* Feature Extraction:
  EEG features were extracted based on sentence-level and fixation-based time segments from eye-tracking data.
  Artifact Rejection:Trials with transient noise exceeding 90μV were excluded.

3. Literature Review:


3. Methods and Materials:

3.1 Model Pipeline:



3.2 Modification for Embedding Layer:


3.3 Implementation Details:

A BERT-based transformer model is effectively leveraged to acquire token representations, a process that stands at the core of NLP tasks. These acquired representations undergo a normalization process using L2 normalization techniques. Through this process, every individual word is meticulously embedded into a 768-dimensional vector, consequently giving rise to a tensor characterized by dimensions of [N × M × 768], wherein N denotes the total count of sentences while M signifies the maximum number of words within a sentence. In order to maintain uniformity and coherence across all sentences, a padding mechanism is systematically employed to address any fluctuations in sentence length that may arise.
 
The eye-gaze analysis delves into the extraction of pertinent features from the ZuCo dataset, an endeavor that encompasses a rich array of 12 distinct features inclusive of metrics such as the Number of Fixations and Mean Pupil Size. To effectively encapsulate the reading attention inherent within the eye-gaze data, L1 normalization techniques are deftly applied to each eye-gaze feature within the inherent sentence dimension.
 
For EEG data, the methodology embraces the application of the conditional entropy method as a robust mechanism for feature extraction, ultimately culminating in the establishment of a feature dimension spanning 5460. Instances characterized by the absence of fixations are systematically assigned zero vectors. In scenarios where words are associated with multiple fixations, a meticulous application of the L2 norm to each vector is followed by an element-wise addition process. This systematic approach ensures the crafting of a comprehensive and holistic representation of the intricate behavioral patterns encapsulated within the realms of eye-gaze and EEG data.
 
Diverging from the conventional concatenation approach, each unique feature undergoes a transformative process wherein it is projected into a communal space characterized by 128 dimensions. Subsequently, a harmonious fusion of EEG and eye-gaze features unfolds through a meticulous process of element-wise addition. Post the projection phase, a strategic integration of sinusoidal positional encoding is meticulously applied prior to the seamless infusion of these features into the transformer encoder for further processing and analysis.
 
In the subsequent stagese, a Multi-Layer Perceptron (MLP) emerges as a pivotal component, serving as the bedrock for predicting the probabilities linked to input samples being affiliated with a specific label within the overarching context of this binary classification task. This methodological approach, characterized by its comprehensive nature, ensures a meticulous and thorough integration of both eye-gaze and EEG features, thereby paving the way for a nuanced and in-depth analysis of behavioral patterns.

3.4 Results and Evaluation:
#+CAPTION:show t-SNE visualizations showing the clustering of low- and high-relevance Reading Embeddings
[[file:../Figures/Results_fig/Reading_embeddings.png]]

#+CAPTION:show t-SNE visualizations showing the clustering of low- and high-relevance word  Embeddings
[[file:../Figures/Word_embeddings3.png]]
